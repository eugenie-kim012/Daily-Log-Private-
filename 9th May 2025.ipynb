{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0072db4",
   "metadata": {},
   "source": [
    "## 의사결정 나무모델    \n",
    "\n",
    "지도학습 알고리즘 (분류, 회귀)\n",
    "- 레이블 (label), 즉 명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신 러닝 방식\n",
    "- 대표적인 유형: 분류 (Classifification); 학습 데이터로 주어진 데이터의 피쳐와 레이블값(결정값, 클레스값)을 머신 러닝러닝 알고리즘으로 학습해 모델 생성, 새로운 데이터의 미지의 레이블을 예측)\n",
    "\n",
    "직관적인 알고리즘 (이해 쉬움)\n",
    "과대적합되기 쉬운 알고리즘 (트리 깊이 제한 필요)\n",
    "\n",
    "* 분류 모델 (의사 결정 나무, 랜덤 포레스트, xgboost)\n",
    "* 교차검증\n",
    "* 평가 (분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 라이브러리 \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb322d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((284, 30), (285, 30), (284,), (285,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 생성\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "def make_dataset():\n",
    "    iris = load_breast_cancer()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop('target', axis=1), df['target'], test_size=0.5, random_state=1004)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = make_dataset()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d7eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    190\n",
       "0     94\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 확인 (2:1 정도의 값을 가지고 있는 것을 확인하였음)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f2859",
   "metadata": {},
   "source": [
    "## 의사결정나무\n",
    "\n",
    "지도학습(분류)에서 가장 유용하게 사용되고 있는 기법 중 하나입니다.\n",
    "트리의 루트(root)에서 시작해서 정보이득이 최대가 되는 특성으로 데이터를 나눕니다.\n",
    "정보이득(information gain)이 최대가 되는 특성을 나누는 기준(불순도를 측정하는 기준)은 '지니'와 '엔트로피'가 사용됩니다.\n",
    "데이터가 한 종류만 있다면 엔트로피/지니 불순도는 0에 가깝고, 서로 다른 데이터의 비율이 비슷하면 1에 가깝습니다.\n",
    "정보이득(information gain)이 최대라는 것은 불순도를 최소화 하는 방향입니다. (1-불순도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fe3f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9263157894736842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정나무\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=0) #random state 지정하여 항상 값이 같도록 해야해\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred) #예측한 변수를 평가한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc79a2e",
   "metadata": {},
   "source": [
    "3. 의사결정나무 하이퍼파라미터\n",
    "criterion (기본값 gini) : 불순도 지표 (또는 엔트로피 불순도 entropy)\n",
    "max_depth (기본값 None) : 최대 한도 깊이\n",
    "min_samples_split (기본값 2) : 자식 노드를 갖기 위한 최소한의 데이터 수\n",
    "min_samples_leaf (기본값 1) : 리프 노드가 되기 위한 최소 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3617da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228070175438596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 의사결정나무 하이퍼파라미터\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(\n",
    "    criterion = 'entropy', \n",
    "    max_depth = 7, # max_depth 튜닝에 따라 값이 달라질 것\n",
    "    min_samples_split = 2, #적어도 2개 이상이 되어야 자식 노드가 생김\n",
    "    min_samples_leaf=2, #역시 튜닝 값에 따라 값이 달라짐\n",
    "    random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07f576",
   "metadata": {},
   "source": [
    "## 랜덤포레스트\n",
    "- 의사결정 나무가 여러 개 있는 것을 랜덤포레스트\n",
    "- 지도 학습 알고리즘 (분류, 회귀)\n",
    "- 의사결정나무의 앙상블\n",
    "- 여러개의 의사결정 트리로 구성\n",
    "- 성능이 좋음 (과대적합 가능성 낮음)\n",
    "- 부트 스트랩 샘플링 (데이터셋 중복 허용)\n",
    "- 최종 다수결 투표\n",
    "- 앙상블 \n",
    "> 배깅; 같은 알고리즘으로 여러 모델을 만들어 분류함 (랜덤 포레스트에서 채택하는 방식)\n",
    "> 부스팅; 학습과 예측을 하면서 가중치 반영 (xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13043db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438596491228071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=0) #random state 0으로 고정\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704892",
   "metadata": {},
   "source": [
    "n_estimators (기본값 100) : 트리의 수 - 여러개의 트리가 합쳐져서 포르스트가 되기 때문\n",
    "> 많을 수록 속도는 느려짐\n",
    "\n",
    "criterion (기본값 gini) : 불순도 지표\n",
    "max_depth (기본값 None) : 최대 한도 깊이\n",
    "min_samples_split (기본값 2) : 자식 노드를 갖기 위한 최소한의 데이터 수\n",
    "min_samples_leaf (기본값 1) : 리프 노드가 되기 위한 최소 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbaac89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트 하이퍼파라미터\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=0) \n",
    "#층과 depth를 조정 하면서 정확도를 조정함, \n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d650de",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost 모델 더 알아보기\n",
    "\n",
    "트리 앙상블 중 성능이 좋은 알고리즘\n",
    "eXtreme Gradient Boosting를 줄여서 XGBoost라고 한다.\n",
    "약한 학습기가 계속해서 업데이트를 하며 좋은 모델을 만들어 간다.\n",
    "부스팅(앙상블) 기반의 알고리즘\n",
    "캐글(글로벌 AI 경진대회)에서 뛰어난 성능을 보이면서 인기가 높아짐 (약한 알고리즘이 묶여서 자란다)\n",
    "\n",
    "2. 하이퍼 파라미터의 종류\n",
    "booster (기본값 gbtree) : 부스팅 알고리즘 (또는 dart, gblinear)\n",
    "objective (기본값 binary:logistic) : 이진분류 (다중분류: multi:softmax)\n",
    "max_depth (기본값 6) : 최대 한도 깊이\n",
    "learning_rate (기본값 0.1) : 학습률\n",
    "n_estimators (기본값 100) : 트리의 수\n",
    "subsample (기본값 1) : 훈련 샘플 개수의 비율\n",
    "colsample_bytree (기본값 1) : 특성 개수의 비율\n",
    "n_jobs (기본값 1) : 사용 코어 수 (-1: 모든 코어를 다 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdc67eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py:122: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9508771929824561"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "from xgboost import XGBClassifierㅍ #불러오기\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "#성능이 조금이라도 더 올랄감.. 워닝은 사실 있어도 상관 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278c6aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost 하이퍼파라미터\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss',\n",
    "                      booster = 'gbtree',\n",
    "                      objective = 'binary:logistic',\n",
    "                      max_depth = 5,\n",
    "                      learning_rate = 0.05,\n",
    "                      n_estimators = 500,\n",
    "                      subsample = 1, \n",
    "                      colsample_bytree = 1,\n",
    "                      n_jobs = -1\n",
    "                      \n",
    "                      \n",
    "# - booster(기본값 gbtree): 부스팅 알고리즘 (또는 dart, gblinear)\n",
    "# - objective(기본값 binary:logistic): 이진분류 (다중분류: multi:softmax)\n",
    "# - max_depth(기본값 6): 최대 한도 깊이\n",
    "# - learning_rate(기본값 0.1): 학습률 - 기울기가 0인 점을 찾아가는 과정; x^2에서 미분하여 내려가는 과정\n",
    "# - n_estimators(기본값 100): 트리의 수\n",
    "# - subsample(기본값 1): 훈련 샘플 개수의 비율\n",
    "# - colsample_bytree(기본값 1): 특성 개수의 비율\n",
    "# - n_jobs(기본값 1): 사용 코어 수 (-1: 모든 코어를 다 사용)\n",
    "                     )\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa7ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65391\n",
      "[1]\tvalidation_0-logloss:0.61861\n",
      "[2]\tvalidation_0-logloss:0.58697\n",
      "[3]\tvalidation_0-logloss:0.55756\n",
      "[4]\tvalidation_0-logloss:0.53038\n",
      "[5]\tvalidation_0-logloss:0.50611\n",
      "[6]\tvalidation_0-logloss:0.48363\n",
      "[7]\tvalidation_0-logloss:0.46304\n",
      "[8]\tvalidation_0-logloss:0.44332\n",
      "[9]\tvalidation_0-logloss:0.42512\n",
      "[10]\tvalidation_0-logloss:0.40821\n",
      "[11]\tvalidation_0-logloss:0.39260\n",
      "[12]\tvalidation_0-logloss:0.37838\n",
      "[13]\tvalidation_0-logloss:0.36512\n",
      "[14]\tvalidation_0-logloss:0.35276\n",
      "[15]\tvalidation_0-logloss:0.34090\n",
      "[16]\tvalidation_0-logloss:0.33018\n",
      "[17]\tvalidation_0-logloss:0.31967\n",
      "[18]\tvalidation_0-logloss:0.30998\n",
      "[19]\tvalidation_0-logloss:0.30105\n",
      "[20]\tvalidation_0-logloss:0.29259\n",
      "[21]\tvalidation_0-logloss:0.28478\n",
      "[22]\tvalidation_0-logloss:0.27725\n",
      "[23]\tvalidation_0-logloss:0.27027\n",
      "[24]\tvalidation_0-logloss:0.26359\n",
      "[25]\tvalidation_0-logloss:0.25755\n",
      "[26]\tvalidation_0-logloss:0.25139\n",
      "[27]\tvalidation_0-logloss:0.24593\n",
      "[28]\tvalidation_0-logloss:0.24103\n",
      "[29]\tvalidation_0-logloss:0.23648\n",
      "[30]\tvalidation_0-logloss:0.23197\n",
      "[31]\tvalidation_0-logloss:0.22778\n",
      "[32]\tvalidation_0-logloss:0.22354\n",
      "[33]\tvalidation_0-logloss:0.21985\n",
      "[34]\tvalidation_0-logloss:0.21678\n",
      "[35]\tvalidation_0-logloss:0.21353\n",
      "[36]\tvalidation_0-logloss:0.21061\n",
      "[37]\tvalidation_0-logloss:0.20800\n",
      "[38]\tvalidation_0-logloss:0.20558\n",
      "[39]\tvalidation_0-logloss:0.20268\n",
      "[40]\tvalidation_0-logloss:0.20042\n",
      "[41]\tvalidation_0-logloss:0.19771\n",
      "[42]\tvalidation_0-logloss:0.19510\n",
      "[43]\tvalidation_0-logloss:0.19354\n",
      "[44]\tvalidation_0-logloss:0.19128\n",
      "[45]\tvalidation_0-logloss:0.18976\n",
      "[46]\tvalidation_0-logloss:0.18854\n",
      "[47]\tvalidation_0-logloss:0.18668\n",
      "[48]\tvalidation_0-logloss:0.18535\n",
      "[49]\tvalidation_0-logloss:0.18346\n",
      "[50]\tvalidation_0-logloss:0.18234\n",
      "[51]\tvalidation_0-logloss:0.18057\n",
      "[52]\tvalidation_0-logloss:0.17897\n",
      "[53]\tvalidation_0-logloss:0.17816\n",
      "[54]\tvalidation_0-logloss:0.17703\n",
      "[55]\tvalidation_0-logloss:0.17564\n",
      "[56]\tvalidation_0-logloss:0.17445\n",
      "[57]\tvalidation_0-logloss:0.17335\n",
      "[58]\tvalidation_0-logloss:0.17179\n",
      "[59]\tvalidation_0-logloss:0.17106\n",
      "[60]\tvalidation_0-logloss:0.17022\n",
      "[61]\tvalidation_0-logloss:0.16983\n",
      "[62]\tvalidation_0-logloss:0.16899\n",
      "[63]\tvalidation_0-logloss:0.16851\n",
      "[64]\tvalidation_0-logloss:0.16776\n",
      "[65]\tvalidation_0-logloss:0.16681\n",
      "[66]\tvalidation_0-logloss:0.16665\n",
      "[67]\tvalidation_0-logloss:0.16632\n",
      "[68]\tvalidation_0-logloss:0.16533\n",
      "[69]\tvalidation_0-logloss:0.16539\n",
      "[70]\tvalidation_0-logloss:0.16520\n",
      "[71]\tvalidation_0-logloss:0.16446\n",
      "[72]\tvalidation_0-logloss:0.16442\n",
      "[73]\tvalidation_0-logloss:0.16449\n",
      "[74]\tvalidation_0-logloss:0.16469\n",
      "[75]\tvalidation_0-logloss:0.16493\n",
      "[76]\tvalidation_0-logloss:0.16526\n",
      "[77]\tvalidation_0-logloss:0.16542\n",
      "[78]\tvalidation_0-logloss:0.16545\n",
      "[79]\tvalidation_0-logloss:0.16448\n",
      "[80]\tvalidation_0-logloss:0.16470\n",
      "[81]\tvalidation_0-logloss:0.16494\n",
      "[82]\tvalidation_0-logloss:0.16506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조기종료\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss', \n",
    "                     learning_rate = 0.05,\n",
    "                      n_estimators = 500)\n",
    "eval_set = [(X_test, y_test)] #검증할 데이터를 가져오는 것\n",
    "model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=10) #학습할 데이터도 가져와야 함\n",
    "#10번 이상 성능 향상이 없다면 종료하겠다\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed17c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508771929824561"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#워닝 없애기\n",
    "\n",
    "#xgboost\n",
    "from xgboost import XGBClassifier #불러오기\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "accuracy_score(y_test, pred)\n",
    "#성능이 조금이라도 더 올랄감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdc3f4",
   "metadata": {},
   "source": [
    "3-5. 교차검증\n",
    "\n",
    "교차검증\n",
    "일반적으로 모델을 학습시킬 때 데이터를 train set과 test set으로 나누어 train set을 가지고 학습을 수행합니다.\n",
    "교차검증이란 여기서 train set을 다시 train set과 validation set으로 나누어 학습 중 검증과 수정을 수행하는 것을 의미합니다 (각각의 모델 데이터, 실습 데이터로 써서 정확성을 검증)\n",
    "\n",
    "Kfold\n",
    "일반적으로 사용되는 교차 검증 기법\n",
    "StratifiedKfold\n",
    "불균형한 타겟 비율을 가진 데이터가 한쪽으로 치우치는 것을 방지\n",
    "사이킷런 교차검증\n",
    "사이킷런 내부 API를 통해 fit(학습) - predict(예측) - evaluation(평가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998f9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "def make_dataset2():\n",
    "    iris = load_breast_cancer()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['target'] = iris.target\n",
    "    return df.drop('target', axis=1), df['target']\n",
    "X, y = make_dataset2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c227c2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771929824561403\n",
      "0.9122807017543859\n",
      "0.9473684210526315\n",
      "0.9385964912280702\n",
      "0.8407079646017699\n"
     ]
    }
   ],
   "source": [
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(X): #하나씩 인덱스로 지정, 검증 데이터로 사용\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949727e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035087719298246\n",
      "0.9210526315789473\n",
      "0.9122807017543859\n",
      "0.9473684210526315\n",
      "0.9026548672566371\n"
     ]
    }
   ],
   "source": [
    "# Stratified Kfold\n",
    "# StratifiedKfold\n",
    "# 불균형한 타겟 비율을 가진 데이터가 한쪽으로 치우치는 것을 방지\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(X, y): #타겟을 넣어서 불균형 방지\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeba9d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88947368, 0.94210526, 0.86243386])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=3) #모델을 넣어 x data, y data를 비교\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3323d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980042699340944"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균 점수\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ad6795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90350877, 0.92105263, 0.9122807 , 0.94736842, 0.90265487])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차검증 Stratified Kfold\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c0362a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173730787144851"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균 점수\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c56f1a38",
   "metadata": {},
   "source": [
    "평가 (분류 모델)\n",
    "정확도 accuracy: 실제 값과 예측값이 일치하는 비율\n",
    "정밀도 precision: 양성이라고 예측한 값 중 실제 양성인 값의 비율 (암이라고 예측 한 값 중 실제 암)\n",
    "재현율 recall: 실제 양성 값 중 양성으로 예측한 값의 비율 (암을 암이라고 판단); 정밀도와 재현률은 Trade-off 관계\n",
    "F1: 정밀도와 재현율의 조화평균\n",
    "ROC-AUC\n",
    "ROC: 참 양성 비율(True Positive Rate)에 대한 거짓 양성 비율(False Positive Rate) 곡선\n",
    "AUC: ROC곡선 면적 아래 (완벽하게 분류되면 AUC가 1임)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9559c245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9026548672566371"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6181643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정밀도\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2e6aebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873239436619719"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 재현율\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ae72fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197080291970803"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b56ddf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999664654594232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "model = XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict_proba(X_test)\n",
    "roc_auc_score(y_test, pred[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
